{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mytools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_name_paths(\n",
    "                    path=r'D:\\UP',\n",
    "                    find=None ,\n",
    "                    case_sensitive=False):\n",
    "    path_collection=[]\n",
    "    for dirpath,dirnames,filenames in os.walk(path):\n",
    "            for file in filenames:\n",
    "                    fullpath=os.path.join(dirpath,file)\n",
    "                    if '~$' not in file.upper():\n",
    "                        if case_sensitive:\n",
    "                            if find:\n",
    "                                if find in file:\n",
    "                                    path_collection.append(fullpath)\n",
    "                            else:\n",
    "                                path_collection.append(fullpath)\n",
    "                        else:\n",
    "                            if find:\n",
    "                                if find.upper() in file.upper():\n",
    "                                    path_collection.append(fullpath)\n",
    "                            else:\n",
    "                                path_collection.append(fullpath)\n",
    "                    else:\n",
    "                        pass\n",
    "    return path_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = file_name_paths(path=r'G:/1-规划/MRO/2.日常mro/需监控的mro文件/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#求多边形的质心并且赋值给lon和lat 拆分\n",
    "kongd_valid[['lon','lat']] = kongd_valid.apply(lambda x:pd.Series(x['geometry'].centroid.coords[:][0]),axis=1)#\n",
    "#将元祖分裂，分成多列\n",
    "kongd_valid[['lon', 'lat']] =kongd_valid['lonlat2'].apply(lambda x: pd.Series(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('G:/1-规划/MRO/1、原始数据/摸底测试相关/2020年/5月/软采/原始数据/05cgi.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.replace(regex=[r'\\''],value='')#替换df中的特殊符号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = [i.replace('\\'','') for i in list(data.columns)]#替换标题中的特殊符号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'A': list('aabcbcccbbc'), \n",
    "                   'B': list('qieyrhfjdnc')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({'A': list('kka'), \n",
    "                   'C': list('asz')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.merge(df2,on='A',validate='m:m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "从 NumPy 数组创建 DataFrame\n",
    "dates = pd.date_range('today',periods=6) # 定义时间序列作为 index\n",
    "num_arr = np.random.randn(6,4) # 传入 numpy 随机数组\n",
    "columns = ['A','B','C','D'] # 将列表作为列名\n",
    "df1 = pd.DataFrame(num_arr, index = dates, columns = columns)\n",
    "df1\n",
    "\n",
    "显示DataFrame的基础信息，包括行的数量；列名；每一列值的数量、类型\n",
    "df.info()    df.describe()\n",
    "\n",
    "\n",
    "取出索引为[3, 4, 8]行的animal和age列\n",
    "df.loc[df.index[[3, 4, 8]], ['animal', 'age']]\n",
    "\n",
    "取出age值缺失的行\n",
    "df[df['age'].isnull()]\n",
    "\n",
    "在df中插入新行k，然后删除该行\n",
    "df.loc['k'] = [5.5, 'dog', 'no', 2]\n",
    "df = df.drop('k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "计算df中每个种类animal的数量\n",
    "df['animal'].value_counts()\n",
    "\n",
    "先按age降序排列，后按visits升序排列\n",
    "df.sort_values(by=['age', 'visits'], ascending=[False, True])\n",
    "\n",
    "将priority列中的yes, no替换为布尔值True, False\n",
    "df['priority'] = df['priority'].map({'yes': True, 'no': False})\n",
    "\n",
    "将animal列中的snake替换为python\n",
    "df['animal'] = df['animal'].replace('snake', 'python')\n",
    "\n",
    "\n",
    "对每种animal的每种不同数量visits，计算平均age，即，返回一个表格，行是aniaml种类，列是visits数量，表格值是行动物种类列访客数量的平均年龄\n",
    " \n",
    "df.pivot_table(index='animal', columns='visits', values='age', aggfunc='mean')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "有一列整数列A的DatraFrame，删除数值重复的行\n",
    "方法一：df1 = df.loc[df['A'].shift() != df['A']]\n",
    "方法二：df1 = df.drop_duplicates(subset='A')\n",
    "\n",
    "一个全数值DatraFrame，每个数字减去该行的平均数\n",
    "df = pd.DataFrame(np.random.random(size=(5, 3)))\n",
    "df1 = df.sub(df.mean(axis=1), axis=0)\n",
    "\n",
    "一个有5列的DataFrame，求哪一列的和最小\n",
    "df = pd.DataFrame(np.random.random(size=(5, 5)), columns=list('abcde'))\n",
    "df.sum().idxmin()\n",
    "\n",
    "给定DataFrame，求A列每个值的前3大的B的和\n",
    "df = pd.DataFrame({'A': list('aaabbcaabcccbbc'), \n",
    "                   'B': [12,345,3,1,45,14,4,52,54,23,235,21,57,3,87]})\n",
    "df1 = df.groupby('A')['B'].nlargest(3).sum(level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "给定DataFrame，有列A, B，A的值在1-100（含），对A列每10步长，求对应的B的和\n",
    "df = pd.DataFrame({'A': [1,2,11,11,33,34,35,40,79,99], \n",
    "                   'B': [1,2,11,11,33,34,35,40,79,99]})\n",
    "df1 = df.groupby(pd.cut(df['A'], np.arange(0, 101, 10)))['B'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "给定DataFrame，计算每个元素至左边最近的0（或者至开头）的距离，生成新列y\n",
    "df = pd.DataFrame({'X': [7, 2, 0, 3, 4, 2, 5, 0, 3, 4]})\n",
    "izero = np.r_[-1, (df['X'] == 0).to_numpy().nonzero()[0]] # 标记0的位置\n",
    "idx = np.arange(len(df))\n",
    "df['Y'] = idx - izero[np.searchsorted(izero - 1, idx) - 1]\n",
    "print(df)\n",
    "\n",
    "方法二\n",
    "x = (df['X'] != 0).cumsum()\n",
    "y = x != x.shift()\n",
    "df['Y'] = y.groupby((y != y.shift()).cumsum()).cumsum()\n",
    "\n",
    "方法三\n",
    "df['Y'] = df.groupby((df['X'] == 0).cumsum()).cumcount()\n",
    "first_zero_idx = (df['X'] == 0).idxmax()\n",
    "df['Y'].iloc[0:first_zero_idx] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "一个全数值的DataFrame，返回最大3值的坐标\n",
    "df = pd.DataFrame(np.random.random(size=(5, 3)))\n",
    "df.unstack().sort_values()[-3:].index.tolist()\n",
    "\n",
    "给定DataFrame，将负值代替为同组的平均值\n",
    "df = pd.DataFrame({'grps': list('aaabbcaabcccbbc'), \n",
    "                   'vals': [-12,345,3,1,45,14,4,-52,54,23,-235,21,57,3,87]})\n",
    "def replace(group):\n",
    "    mask = group<0\n",
    "    group[mask] = group[~mask].mean()\n",
    "    return group\n",
    "df['vals'] = df.groupby(['grps'])['vals'].transform(replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "计算3位滑动窗口的平均值，忽略NAN\n",
    "df = pd.DataFrame({'group': list('aabbabbbabab'),\n",
    "                 'value': [1, 2, 3, np.nan, 2, 3, np.nan, 1, 7, 3, np.nan, 8]})\n",
    "g1 = df.groupby(['group'])['value']\n",
    "g2 = df.fillna(0).groupby(['group'])['value'] \n",
    "s = g2.rolling(3, min_periods=1).sum() / g1.rolling(3, min_periods=1).count()\n",
    "s.reset_index(level=0, drop=True).sort_index() \n",
    "\n",
    "创建Series s，将2015所有工作日作为随机值的索引\n",
    "dti = pd.date_range(start='2015-01-01', end='2015-12-31', freq='B') \n",
    "s = pd.Series(np.random.rand(len(dti)), index=dti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "所有礼拜三的值求和\n",
    "s[s.index.weekday == 2].sum() \n",
    "求每个自然月的平均数\n",
    "s.resample('M').mean()\n",
    "\n",
    "每连续4个月为一组，求最大值所在的日期\n",
    "s.groupby(pd.Grouper(freq='4M')).idxmax()\n",
    "\n",
    "创建2015-2016每月第三个星期四的序列\n",
    "pd.date_range('2015-01-01', '2016-12-31', freq='WOM-3THU')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "数据清洗\n",
    "df = pd.DataFrame({'From_To': ['LoNDon_paris', 'MAdrid_miLAN', 'londON_StockhOlm', \n",
    "                               'Budapest_PaRis', 'Brussels_londOn'],\n",
    "              'FlightNumber': [10045, np.nan, 10065, np.nan, 10085],\n",
    "              'RecentDelays': [[23, 47], [], [24, 43, 87], [13], [67, 32]],\n",
    "              'Airline': ['KLM(!)', '<Air France> (12)', '(British Airways. )',              '12. Air France', '\"Swiss Air\"']})\n",
    " \n",
    "FlightNumber列中有些值缺失了，他们本来应该是每一行增加10，填充缺失的数值，并且令数据类型为整数\n",
    "df['FlightNumber'] = df['FlightNumber'].interpolate().astype(int)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "将From_To列从_分开，分成From, To两列，并删除原始列\n",
    "temp = df.From_To.str.split('_', expand=True)\n",
    "temp.columns = ['From', 'To']\n",
    "df = df.join(temp)\n",
    "df = df.drop('From_To', axis=1)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "将From, To大小写统一\n",
    "df['From'] = df['From'].str.capitalize()\n",
    "df['To'] = df['To'].str.capitalize()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Airline列，有一些多余的标点符号，需要提取出正确的航司名称。举例：'(British Airways. )' 应该改为 'British Airways'.\n",
    "df['Airline'] = df['Airline'].str.extract('([a-zA-Z\\s]+)', expand=False).str.strip()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RecentDelays列，数据被以列表的形式录入，但是我们希望每个数字被录入成单独一列，delay_1, delay_2, ...没有的用NAN替代\n",
    "delays = df['RecentDelays'].apply(pd.Series)\n",
    "delays.columns = ['delay_{}'.format(n) for n in range(1, len(delays.columns)+1)]\n",
    "df = df.drop('RecentDelays', axis=1).join(delays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.random(size=(5, 5)), columns=list('abcde'))\n",
    "df.sum(axis=1).idxmin()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'A': list('aaabbcaabcccbbc'), \n",
    "                   'B': [12,345,3,1,45,14,4,52,54,23,235,21,57,3,87]})\n",
    "df1 = df.groupby('A')['B'].nlargest(3).sum(level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('A')['B'].nlargest(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isdigit( ), islower( ), isupper( ), isalpha( ) , isspace( )这几个函数在算法题里面还是很有用处的。\n",
    "\n",
    "isdigit( )  检测字符串是否只由数字组成。  和 isnumeric( )函数类似\n",
    "\n",
    "islower( )   检测字符串是否由小写字母组组成\n",
    "\n",
    "isupper( )  检测字符串中所有的字母是否都为大写\n",
    "\n",
    "isalpha( )  检测字符串是否只由字母组成\n",
    "\n",
    "isspace( )  检测字符串是否只由空格组成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas消除空值和空格以及 Nan数据替换方法\n",
    "(df[\"VIN\"].isnull()) | (df[\"VIN\"].apply(lambda x: str(x).isspace()))\n",
    "df[\"VIN\"]=df[\"VIN\"].apply(lambda x: np.NaN if str(x).isspace() else x)\n",
    "df_null = df[df[\"VIN\"].isnull()]\n",
    "df_not_null = df[df[\"VIN\"].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_inlist(list_x , str=['ca']):\n",
    "    list_a = []\n",
    "    for x in enumerate(list_x):\n",
    "        for y in str:\n",
    "            if y in x[1]:\n",
    "                list_a.append(x[1])\n",
    "    return list_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ['a','b','c','d']\n",
    "b = ['a']\n",
    "c = ['c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fgl['全网移动覆盖率'] = data_fgl['全网移动覆盖率'].apply(lambda x: format(x, '.2%'))    #Series.apply()让序列的值依次在lambda函数中执行； data['线损率']由小数转化为百分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#循环第一种方法\n",
    "kml = simplekml.Kml()\n",
    "#-----------------------------------循环其他经纬度\n",
    "for i in range(len(data.index)):\n",
    "    row_v = data.iloc[i,:]\n",
    "    mingcheng,lon_p,lat_p = row_v[['小区中文名','RRU经度','RRU纬度']] # +++++++++++++++++++++++名称和经纬度必须\n",
    "    \n",
    "    #------------创建点\n",
    "    pnt = kml.newpoint(name=mingcheng )#\n",
    "    pnt.coords = [(lon_p, lat_p)] \n",
    "kml.save(\"botanicalgarden_1.kml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#循环第二种方法\n",
    "def apply_kml_for(df):\n",
    "    df.apply(lambda row: guocheng(row),axis=1)\n",
    "    \n",
    "def guocheng(row):\n",
    "    mingcheng,lon_p,lat_p = row[['小区中文名','RRU经度','RRU纬度']] # +++++++++++++++++++++++名称和经纬度必须\n",
    "    #------------创建点\n",
    "    pnt = kml.newpoint(name=mingcheng )#\n",
    "    pnt.coords = [(lon_p, lat_p)] \n",
    "\n",
    "\n",
    "kml = simplekml.Kml()\n",
    "#-----------------------------------循环其他经纬度\n",
    "apply_kml_for(data)\n",
    "kml.save(\"botanicalgarden_2.kml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#循环第三种方法\n",
    "def guocheng1(name , lon_p,lat_p):\n",
    "    #------------创建点\n",
    "    pnt = kml.newpoint(name=name )#\n",
    "    pnt.coords = [(lon_p, lat_p)] \n",
    "\n",
    "kml = simplekml.Kml()\n",
    "for x in zip(data['小区中文名'], data['RRU经度'], data['RRU纬度']):\n",
    "    guocheng1(*x)\n",
    "kml.save(\"botanicalgarden_3.kml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wt_cell[\"覆盖类别\"]=wt_cell[\"覆盖类别\"].fillna(3)#na的用3填充 na null 填充\n",
    "data2=data.groupby(by = 'id').apply(lambda g:g['da'].str.cat(sep='/'))#多列合成一列，分组后，行转列\n",
    "\n",
    "df_use = pd.DataFrame(df.groupby(by = 'CGI_left').apply(lambda g:g['CGI_right'].str.cat(sep='/'))).reset_index()#转成dataframe\n",
    "df_use.columns=['sdfsdfs']\n",
    "\n",
    "df1 = (df.drop('合并', axis=1).join(df['合并'].str.split('#', expand=True).stack().reset_index(level=1, drop=True).rename('合并')))#列转行，一列分隔符转多行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(b).difference(set(a))#对比两个列表的差异 listA对应listB的差集\n",
    "set(listA).intersection(set(listB))#交集\n",
    "set(listA).union(set(listB))#并集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['B'] = df['B'].mask(df['A']==2,'sdf')  #where 和 mask类似于slq的update\n",
    "df.where(df !=N).dropna(axis = 1)  #去掉特定的某行某列\n",
    "df.loc[(df['A']==0) | (df['A']==4),'data']='rr' #更新满足条件的数据，本表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#行转列 方法一\n",
    "n_lst=[]\n",
    "for index_n,row_n in data_y.iterrows():\n",
    "    n_nm=row_n['小区中文名']\n",
    "    for i in range(len(row_n['DUIYING'])):\n",
    "        dict_n={}\n",
    "        dict_n['小区中文名']=n_nm\n",
    "        n_id=row_n['DUIYING'][i]\n",
    "        dict_n['ID']=n_id\n",
    "        n_lst.append(dict_n)\n",
    "df_n=pd.DataFrame(n_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame({'key':['a','b','c'],'value1':range(3)})\n",
    "df2=pd.DataFrame({'key':['a','b','b'],'value2':range(4,7)})\n",
    "display(df1,df2,pd.merge(df1,df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_r_grid['a.un_maxrsrp_weak_l2'] = data_r_grid['a.un_maxrsrp_weak_l2'].str.replace(r'\\r','')#替换表中的换行 \\r符号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#实现sql的update功能，关联两个表的id列，更新匹配到的数据\n",
    "data = pd.merge(data1, data2, left_on='CGI', right_on='CGI2', how='left')\n",
    "data['name'] = data.apply(lambda x: x['name2'] if(pd.notna(x['CGI2'])) else x['name'], axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分组，组内排序，查询前几行\n",
    "data_r_cell_7y16_max = data_r_cell_7y16.groupby(by = 'eutrancell_cgi').apply(lambda x\n",
    "                                                                             :x.nlargest(1,'rsrp_sample_count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'A': [11, 12, 13],'B': [14, 15, 16]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame({'B': [21, 22,23],'C': [24, 25, 26]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.update(new_df)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'A': ['a1', 'a2', 'a3'], 'B': ['b1', 'b2', 'b3']})\n",
    "new_df = pd.DataFrame({'B': ['c1', 'c2', 'c3', 'c4', 'c5']})\n",
    "df1.update(new_df)\n",
    "df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df1,new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df1,new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_r_cell_z1=data_r_cell_z.sort_values(by=\"rsrp_count\",ascending= False)  #排序 升序True 降序False by列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text=pd.read_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa=data_text.groupby(by = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[a for a in aa ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text.groupby(by = 'id').apply(lambda x:x.nlargest(1,'数量'))#分组后保留最大的某个列的一行，排序，降序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_dd=data_text.drop_duplicates('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dd2 = data_dd[['id', 'id2','数量', 'id3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([data_dd,data_dd2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q=pd.read_excel('D:/规划/11全网扇区图层-武汉.xlsx',encoding = 'gbk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from math import *\n",
    "# ss1=pd.read_clipboard()#粘贴板复制到dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uu=pd.read_sql('xxx.sql')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = pd.read_csv(open('问题小区2.csv'))\n",
    "data_2 = pd.read_csv(open('问题小区.csv'))\n",
    "display(data_1.shape,data_1.head(1),data_1.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = pd.merge(data_1,data_2, how = 'inner',left_on='cgi' , right_on = 'cgi') #连接相当于join\n",
    "ss = ss.drop_duplicates('cgi') #去除重复\n",
    "\n",
    "#平时使用最多的筛选应该是字符串的模糊筛选，在SQL语句里用的是like，在pandas里我们可以用.str.contains()来实现。\n",
    "\n",
    "print(len(ss.index)) #获取行数\n",
    "print(ss.shape[0]) #获取行数\n",
    "print(len(ss))#获取行数\n",
    "\n",
    "print(ss.shape[1]) #获取列数\n",
    "print(ss.shape)#获取行和列数\n",
    "print(ss.columns.size)#获取列数\n",
    "\n",
    "df = df.drop(df[(df.score < 50) & (df.score > 20)].index) #多条件删除，符合条件的行\n",
    "\n",
    "res_zong_j3.loc[res_zong_j3['小区中文名_left'].str.contains('美化'),'优先级']= 9 #筛选并赋值，筛选条件并更新值\n",
    "\n",
    "read_data=read_data[ ~ read_data['type'].str.contains('未知')]  #删除某列包含特殊字符，过滤删除，筛选剔除\n",
    "\n",
    "ss['cgi'] = ss['cgi'].str.replace('\\n', '')#删除换行符：\n",
    "ss[\"cgi\"] = ss[\"cgi\"].map(str.strip)#删除字符串前后空格：\n",
    "print(ss[0:2])     #\n",
    "print(ss.columns)       #列索引名称\n",
    "print(ss.index)       #行索引名称\n",
    "\n",
    "print(ss.ix[1])               #取第2行数据\n",
    "print(ss.iloc[1])             #取第2行数据\n",
    "print(ss['cgi'])      #取列索引为x的一列数据\n",
    "print(ss.loc[1])     #取第行索引为”A“的一行数据，\n",
    "\n",
    "print(ss.loc[:,['cgi','fw']])          #表示选取所有的行以及columns为a,b的列；\n",
    "print(ss.loc[[1,4],['cgi','fw']])     #表示选取'A'和'B'这两行以及columns为x,z的列的并集；\n",
    "\n",
    "print(ss.iloc[1:3,1:3])              #数据切片操作，切连续的数据块\n",
    "print(ss.iloc[[0,2],[1,2]])              #即可以自由选取行位置，和列位置对应的数据，切零散的数据块\n",
    "\n",
    "print(ss[ss['cgi'].isin(['460-00-168243-64','460-00-444767-1'])])    #表显示满足条件：列y中的值包含'6','8'的所有行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame({'key':['b','b','a','a','b','a','c'],'data1':range(7),'data2':range(2,9)})\n",
    "print(df1.mean())#默认对每一列的数据求平均值；若加上参数a.mean(1)则对每一行求平均值\n",
    "print(df1['data2'].value_counts()) #统计某一列x中各个值出现的次数：\n",
    "print(df1.describe()) #对每一列数据进行统计，包括计数，均值，std，各个分位数等。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.sort_values(['data2'],ascending=False).head(4)#True升序 False降序,显示前10项\n",
    "df1.loc[df1['data2'] == 2,[\"data1\", \"key\"]].head().sort([\"data2\"],ascending=False)#单列数据筛选  （!=）  [\"data1\", \"key\"]不选显示全部"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1.loc[(df1[\"data1\"] >2 ) & (df1[\"data2\"]<7), [\"data1\", \"key\",'data2']].head()#多列数据筛选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(gongcan_res['小区CGI(*)'].str.split('-',expand=True)[2])#筛选，分裂，cgi转enodeb\n",
    "gongcan_res['enodeb']=gongcan_res['小区CGI(*)'].str.split('-',expand=True)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1.loc[df1[\"data1\"] >4].data1.sum() #按筛选条件求和(sumif, sumifs)\n",
    "df1.loc[(df1[\"data1\"] >2) & (df1[\"data2\"] <7)].data1.sum()#相当于excel中的sumif\n",
    "df1.loc[(df1[\"data1\"] >2) & (df1[\"data2\"] <7)].data1.count()#相当于excel中的countif\n",
    "df1.loc[(df1[\"data1\"] >2) & (df1[\"data2\"] <7)].data1.mean()#相当于excel中的averageif\n",
    "#max，min等同理\n",
    "\n",
    "df1[df1>2]      #表示选取数据集中大于0的数据\n",
    "df1[df1.data1>2]      #表示选取数据集中x这一列大于5的所有的行\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*-coding:utf-8-*-\n",
    "\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "    获取行列数据\n",
    "\"\"\"\n",
    "df = DataFrame(np.random.rand(4, 5), columns=['A', 'B', 'C', 'D', 'E'])\n",
    "df['col_sum'] = df.apply(lambda x: x.sum(), axis=1)  # 横向求和，axis=1表示横向\n",
    "df.loc['row_sum'] = df.apply(lambda x: x.sum())  # loc获取一整列的数据，对一列数据进行求和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = pd.DataFrame(np.arange(0, 60, 2).reshape(10, 3), columns=list('abc'))\n",
    "# loc获取一整列的数据\n",
    "dd.loc[0:len(dd), 'a']\n",
    "dd.loc[0:3, ['a', 'b']]\n",
    "dd.loc[[1, 5], ['b', 'c']]\n",
    "\n",
    "# iloc获取某个位置的元素，或者某个区域的元素\n",
    "dd.iloc[1, 1]\n",
    "dd.iloc[0:3, [0, 1]]\n",
    "dd.iloc[[0, 3, 5], 0:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#去重函数 drop_duplicates()\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "data = DataFrame({'k': [1, 1, 2, 2]})\n",
    "data.duplicated()  # duplicated()判断是否是重复的项\n",
    "type(isduplicates)\n",
    "data.drop_duplicates()  # drop_duplicates()移除重复的项\n",
    "\n",
    "new_df = df.drop_duplicates(subset='name',keep='first',inplace=False) #按name 去重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=s.to_frame()#如何将Series转为DataFrame\n",
    "\"\"\"\n",
    "    Pandas.DataFrame 读取、合并、修改列数据、新增列、分组、分组数据计算\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "from datetime import timedelta, datetime\n",
    "from dateutil.parser import parse\n",
    "\n",
    "\"\"\"\n",
    "    读写csv文件\n",
    "\"\"\"\n",
    "# 读取csv文件\n",
    "df = pd.read_csv('data_english.csv', encoding='gbk')\n",
    "# print df\n",
    "print type(df)  # <class 'pandas.core.frame.DataFrame'>\n",
    "print df.columns  # 所有列的标签\n",
    "print df.index  # 所有行的标签\n",
    "print df.book_id  # 选择某一列，可以使用df.book_id ，也可以使用df['book_id']\n",
    "print type(df.book_id)  # <class 'pandas.core.series.Series'>\n",
    "print np.array(df.book_id)  # 将Series转换为numpy的darray格式\n",
    "print '---------------------------------------------------------'\n",
    "\n",
    "# 写入csv文件\n",
    "# df.to_csv('dat.csv', index=False, encoding='gbk')  # index=False表示不把index写入文件\n",
    "\n",
    "\"\"\"\n",
    "    行列的选取\n",
    "\"\"\"\n",
    "print df.read_name  # 选择一列\n",
    "print df[:3]  # 选择前3行\n",
    "print df.loc[:, ('read_num', 'read_name')]  # df.loc[行标签，列标签]\n",
    "print df.iloc[2, 4]  # df.iloc[行位置，列位置]\n",
    "print df.ix[2, 4]  # df.ix[行位置或行标签，列位置或列标签]\n",
    "\n",
    "# bool判断\n",
    "print df[df.read_name == u'山问萍'].head()  # 获取符合条件的行列\n",
    "print df[(df.read_name == u'山问萍') & (df.book == u'植物生理学实验教程')]  # 多个条件\n",
    "print '----------------------------------------------'\n",
    "\n",
    "\"\"\"\n",
    "    两个df相merge\n",
    "\"\"\"\n",
    "# pd.concat([df1, df2])  # 两个df的column都一样，index不重复（增加列）\n",
    "# pd.concat([df1, df2], axis=1)  # 两个df的index都一样，column不重复（增加行）\n",
    "\n",
    "\"\"\"\n",
    "    增加列，删除列，重命名某一列\n",
    "\"\"\"\n",
    "# df['new_col'] = xxx  # 直接增加一列，加到最后一列\n",
    "# df.insert[1, 'new_col']  # 使用df.insert 插入一列，可以设置这一列的位置\n",
    "# del df['one_col']  # 直接使用del进行删除，删除某一列\n",
    "# df = df.rename(columns={'old_name': 'new_name'})  # 重命名某一列\n",
    "# df = df.rename(columns={'old_name': 'new_name'}, inplace=True)\n",
    "# print '--------------------------------------------------------'\n",
    "\n",
    "\"\"\"\n",
    "    apply(): 对dataframe的内容进行批量处理，比循环更快\n",
    "    map(),\n",
    "    agg()：对分组的结果再分别进行不同的操作\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "    数据合并\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data1 = pd.DataFrame({'level': ['a', 'b', 'c', 'd'], 'number': [1, 3, 5, 7]})\n",
    "data2 = pd.DataFrame({'level': ['a', 'b', 'c', 'e'], 'number': [2, 3, 4, 5]})\n",
    "print data1\n",
    "print data2\n",
    "print pd.merge(data1, data2, on='level')  # 合并，内连接\n",
    "\n",
    "data3 = pd.DataFrame({'level1': ['a', 'b', 'c', 'd'], 'number': [1, 3, 5, 7]})\n",
    "data4 = pd.DataFrame({'level2': ['a', 'b', 'c', 'e'], 'number': [2, 3, 4, 5]})\n",
    "print pd.merge(data3, data4, left_on='level1', right_on='level2')\n",
    "print pd.merge(data3, data4, left_on='level1', right_on='level2', how='left')\n",
    "print '----------------------------------------'\n",
    "\"\"\"\n",
    "    merge参数说明：\n",
    "        left和right:两个不同的DataFrame\n",
    "        how:合并的方式-->inner内连接，right右连接，left左连接，outer外连接，默认为inner\n",
    "        on:用于连接的列索引名称，必须存在于两个DataFrame对象中\n",
    "        left_on:\n",
    "        right_on:\n",
    "        left_index:\n",
    "        right_index:\n",
    "        sort:默认为True,将合并的数据进行排序\n",
    "        suffixes:当列名相同时，合并后，自动添加后缀名称，默认为(_x, _y)\n",
    "        copy:默认为True，复制数据结构\n",
    "        indicator:\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "    重叠数据合并\n",
    "\"\"\"\n",
    "data3 = pd.DataFrame({'level': ['a', 'b', 'c', 'd'], 'number1': [1, 3, 5, np.nan]})\n",
    "data4 = pd.DataFrame({'level': ['a', 'b', 'c', 'e'], 'number2': [2, np.nan, 4, 5]})\n",
    "print data3.combine_first(data4)  # 相同标签下的内容优先显示data3的内容，如果某个数据缺失，就用另外一个数据补上\n",
    "\n",
    "\"\"\"\n",
    "    数据重塑和轴向旋转\n",
    "    数据重塑：reshape()\n",
    "    轴向旋转：unstack(),stack()\n",
    "\"\"\"\n",
    "data = pd.DataFrame(np.arange(12).reshape(3, 4), columns=['a', 'b', 'c', 'd'], index=['wang', 'li', 'zhang'])\n",
    "print data\n",
    "print data.unstack()  # 轴向旋转\n",
    "print '---------------------------------'\n",
    "\n",
    "\"\"\"\n",
    "    数据转换\n",
    "\"\"\"\n",
    "data = pd.DataFrame({'a': [1, 3, 3, 4], 'b': [1, 3, 3, 5]})\n",
    "print data\n",
    "print data.duplicated()  # 判断是否重复行\n",
    "print data.drop_duplicates()  # 去除重复行\n",
    "\n",
    "\"\"\"\n",
    "    替换值\n",
    "\"\"\"\n",
    "data = pd.DataFrame({'a': [1, 3, 3, 4], 'b': [1, 3, 3, 5]})\n",
    "print data.replace(1, 2)  # 凡是数据1，全部替换成数据2\n",
    "print data.replace([1, 4], np.nan)  # 凡是数据1，4，全部替换成np.nan\n",
    "\n",
    "\"\"\"\n",
    "    数据分段\n",
    "\"\"\"\n",
    "data = [11, 15, 18, 20, 25, 26, 27, 24]\n",
    "bins = [15, 20, 25]\n",
    "print data\n",
    "print pd.cut(data, bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_1.iloc[:2,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_1['cgi'].str.split('-',expand=True)[0]  ##分裂  -分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2=data_1['cgi'].str[-3:] ##切片 类似于left，取制定区间的字符串。\n",
    "data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "str_list = '[(114.18472, 30.616594), (114.1844500688932, 30.617465279267197)]'\n",
    "list_list = ast.literal_eval(str_list) #将list形式字符转换成list格式\n",
    "list_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
